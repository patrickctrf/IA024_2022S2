{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/patrickctrf/IA024_2022S2/blob/main/ex03/patrick_ferreira/ex03_patrick_ferreira_175480.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "nome = 'Patrick de Carvalho Tavares Rezende Ferreira'\n",
    "print(f'Meu nome é {nome}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxGWfhA5jxNG",
    "outputId": "b528f839-fea5-48d9-fe45-b6ad50538cec"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é Patrick de Carvalho Tavares Rezende Ferreira\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od7iUgHy5SSi"
   },
   "source": [
    "## Instruções\n",
    "\n",
    "- Treinar uma rede neural de duas camadas como classificador binário na tarefa de análise de sentimentos usando dataset IMDB usando TF-IDF como entrada.\n",
    "\n",
    "Deve-se implementar o laço de treinamento e validação da rede neural.\n",
    "\n",
    "Neste exercício usaremos o IMDB com 20k exemplos para treino, 5k para desenvolvimento e 25k para teste."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importando os pacotes necessários"
   ],
   "metadata": {
    "id": "W_dfOgTUffR2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "lb8DJ6YaTtyI"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Verificando se a GPU está disponível"
   ],
   "metadata": {
    "id": "3HA9p2iEUZj-"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPbiUIrHZlun",
    "outputId": "eb43979a-aea8-4074-b6c6-88aafc942ecc"
   },
   "source": [
    "if torch.cuda.is_available(): \n",
    "   dev = \"cuda:0\"\n",
    "   print(torch. cuda. get_device_name(dev))\n",
    "else:\n",
    "   dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce 940MX\n",
      "cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXFdJz2KVeQw"
   },
   "source": [
    "## Preparando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHMi_Kq65fPM"
   },
   "source": [
    "Primeiro, fazemos download do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2wbnfzst5O3k",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f999a0f8-9398-4b72-b5aa-a7cb2d2afa52"
   },
   "source": [
    "!wget -nc http://files.fast.ai/data/aclImdb.tgz \n",
    "!tar -xzf aclImdb.tgz"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘aclImdb.tgz’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Giyi5Rv_NIm"
   },
   "source": [
    "## Carregando o dataset\n",
    "\n",
    "Criaremos uma divisão de treino (80%) e validação (20%) artificialmente.\n",
    "\n",
    "Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0HIN_xLI_TuT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53038c65-ed12-442e-adfe-1cb105fe86b5"
   },
   "source": [
    "def load_texts(folder):\n",
    "    texts = []\n",
    "    for path in os.listdir(folder):\n",
    "        with open(os.path.join(folder, path)) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "x_train_pos = load_texts('aclImdb/train/pos')\n",
    "x_train_neg = load_texts('aclImdb/train/neg')\n",
    "x_test_pos = load_texts('aclImdb/test/pos')\n",
    "x_test_neg = load_texts('aclImdb/test/neg')\n",
    "\n",
    "x_train = x_train_pos + x_train_neg\n",
    "x_test = x_test_pos + x_test_neg\n",
    "y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
    "y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
    "\n",
    "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
    "c = list(zip(x_train, y_train))\n",
    "random.shuffle(c)\n",
    "x_train, y_train = zip(*c)\n",
    "\n",
    "n_train = int(0.8 * len(x_train))\n",
    "\n",
    "x_valid = x_train[n_train:]\n",
    "y_valid = y_train[n_train:]\n",
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "\n",
    "print(len(x_train), 'amostras de treino.')\n",
    "print(len(x_valid), 'amostras de desenvolvimento.')\n",
    "print(len(x_test), 'amostras de teste.')\n",
    "\n",
    "print('3 primeiras amostras treino:')\n",
    "for x, y in zip(x_train[:3], y_train[:3]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 últimas amostras treino:')\n",
    "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 primeiras amostras validação:')\n",
    "for x, y in zip(x_valid[:3], y_test[:3]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 últimas amostras validação:')\n",
    "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
    "    print(y, x[:100])"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 amostras de treino.\n",
      "5000 amostras de desenvolvimento.\n",
      "25000 amostras de teste.\n",
      "3 primeiras amostras treino:\n",
      "False Okay, first off, Seagal's voice is dubbed over for like 50% of the film... Why? Because apparently t\n",
      "True This movie was featured on a very early episode of Mystery Science Theater 3000, but when I see this\n",
      "True This low-budget erotic thriller that has some good points, but a lot more bad one. The plot revolves\n",
      "3 últimas amostras treino:\n",
      "False I thought they should have called this movie \"Whites\" instead of \"Heights\". Godawful...the kind of f\n",
      "False \"Serum\" starts out with credits that are quite reminiscent of the \"Re-animator\" movies, and it owes \n",
      "False *spoliers* do not read any further if you haven't seen this movie<br /><br />Picking up after the de\n",
      "3 primeiras amostras validação:\n",
      "True Typical 90's comedy, situational comedy similar to our modern day \"My Family\". Thatcher being the he\n",
      "True I like Goldie Hawn and wanted another one of her films, so when I saw Protocol for $5.50 at Walmart \n",
      "True At first glance, this film looks like the Keifer Sutherland series 24 for the big screen. With the f\n",
      "3 últimas amostras validação:\n",
      "True Finally, after years of awaiting a new film to continue the sexual mayhem of \"Basic Instinct\", we ha\n",
      "True I found this to be a so-so romance/drama that has a nice ending and a generally nice feel to it. It'\n",
      "True I didn't expect Val Kilmer to make a convincing John Holmes, but I found myself forgetting that it w\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definindo funções de manipulação de texto."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def tokenize(text: str):\n",
    "    \"\"\"\n",
    "    Convert string to a list of tokens (i.e., words).\n",
    "    This function lower cases everything and removes punctuation.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub('[' + string.punctuation + ']', '', text).lower().split()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def create_vocab(texts: List[str], max_tokens: int):\n",
    "    \"\"\"\n",
    "    Returns a dictionary whose keys are tokens and values are token ids (from 0 to max_tokens - 1).\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for t in texts:\n",
    "        tokens.extend(tokenize(t))\n",
    "\n",
    "    return dict(Counter(tokens).most_common(max_tokens))\n",
    "\n",
    "def concatenate_list_of_str(texts: List[str]):\n",
    "    return \"\".join(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criando classe do dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testando dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "x_assert = [\"It is going to rain today.\",\n",
    "            \"Today I am not going outside.\",\n",
    "            \"I am going to watch the season premiere.\"]\n",
    "\n",
    "y_assert = [False, True, True]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}