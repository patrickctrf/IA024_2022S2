{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickctrf/IA024_2022S2/blob/main/ex03/patrick_ferreira/ex03_patrick_ferreira_175480.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = 'COLOQUE SEU NOME AQUI'\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxGWfhA5jxNG",
        "outputId": "b528f839-fea5-48d9-fe45-b6ad50538cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é COLOQUE SEU NOME AQUI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od7iUgHy5SSi"
      },
      "source": [
        "## Instruções\n",
        "\n",
        "- Treinar uma rede neural de duas camadas como classificador binário na tarefa de análise de sentimentos usando dataset IMDB usando TF-IDF como entrada.\n",
        "\n",
        "Deve-se implementar o laço de treinamento e validação da rede neural.\n",
        "\n",
        "Neste exercício usaremos o IMDB com 20k exemplos para treino, 5k para desenvolvimento e 25k para teste."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando os pacotes necessários"
      ],
      "metadata": {
        "id": "W_dfOgTUffR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lb8DJ6YaTtyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificando se a GPU está disponível"
      ],
      "metadata": {
        "id": "3HA9p2iEUZj-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPbiUIrHZlun",
        "outputId": "eb43979a-aea8-4074-b6c6-88aafc942ecc"
      },
      "source": [
        "if torch.cuda.is_available(): \n",
        "   dev = \"cuda:0\"\n",
        "   print(torch. cuda. get_device_name(dev))\n",
        "else:\n",
        "   dev = \"cpu\" \n",
        "print(dev)\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFdJz2KVeQw"
      },
      "source": [
        "## Preparando Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHMi_Kq65fPM"
      },
      "source": [
        "Primeiro, fazemos download do dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wbnfzst5O3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f999a0f8-9398-4b72-b5aa-a7cb2d2afa52"
      },
      "source": [
        "!wget -nc http://files.fast.ai/data/aclImdb.tgz \n",
        "!tar -xzf aclImdb.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-31 11:05:22--  http://files.fast.ai/data/aclImdb.tgz\n",
            "Resolving files.fast.ai (files.fast.ai)... 172.67.69.159, 104.26.3.19, 104.26.2.19, ...\n",
            "Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.fast.ai/data/aclImdb.tgz [following]\n",
            "--2022-08-31 11:05:22--  https://files.fast.ai/data/aclImdb.tgz\n",
            "Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145982645 (139M) [application/x-gtar-compressed]\n",
            "Saving to: ‘aclImdb.tgz’\n",
            "\n",
            "aclImdb.tgz         100%[===================>] 139.22M  20.0MB/s    in 8.1s    \n",
            "\n",
            "2022-08-31 11:05:30 (17.2 MB/s) - ‘aclImdb.tgz’ saved [145982645/145982645]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Giyi5Rv_NIm"
      },
      "source": [
        "## Carregando o dataset\n",
        "\n",
        "Criaremos uma divisão de treino (80%) e validação (20%) artificialmente.\n",
        "\n",
        "Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIN_xLI_TuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53038c65-ed12-442e-adfe-1cb105fe86b5"
      },
      "source": [
        "def load_texts(folder):\n",
        "    texts = []\n",
        "    for path in os.listdir(folder):\n",
        "        with open(os.path.join(folder, path)) as f:\n",
        "            texts.append(f.read())\n",
        "    return texts\n",
        "\n",
        "x_train_pos = load_texts('aclImdb/train/pos')\n",
        "x_train_neg = load_texts('aclImdb/train/neg')\n",
        "x_test_pos = load_texts('aclImdb/test/pos')\n",
        "x_test_neg = load_texts('aclImdb/test/neg')\n",
        "\n",
        "x_train = x_train_pos + x_train_neg\n",
        "x_test = x_test_pos + x_test_neg\n",
        "y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
        "y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
        "\n",
        "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
        "c = list(zip(x_train, y_train))\n",
        "random.shuffle(c)\n",
        "x_train, y_train = zip(*c)\n",
        "\n",
        "n_train = int(0.8 * len(x_train))\n",
        "\n",
        "x_valid = x_train[n_train:]\n",
        "y_valid = y_train[n_train:]\n",
        "x_train = x_train[:n_train]\n",
        "y_train = y_train[:n_train]\n",
        "\n",
        "print(len(x_train), 'amostras de treino.')\n",
        "print(len(x_valid), 'amostras de desenvolvimento.')\n",
        "print(len(x_test), 'amostras de teste.')\n",
        "\n",
        "print('3 primeiras amostras treino:')\n",
        "for x, y in zip(x_train[:3], y_train[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras treino:')\n",
        "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 primeiras amostras validação:')\n",
        "for x, y in zip(x_valid[:3], y_test[:3]):\n",
        "    print(y, x[:100])\n",
        "\n",
        "print('3 últimas amostras validação:')\n",
        "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
        "    print(y, x[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000 amostras de treino.\n",
            "5000 amostras de desenvolvimento.\n",
            "25000 amostras de teste.\n",
            "3 primeiras amostras treino:\n",
            "True It's hard for me to assign the \"fair\" number of stars to this film, but I settled on 8 because of it\n",
            "True \"The Lion King\" is without a doubt my favorite Disney movie of all time, so I figured maybe I should\n",
            "False Mario Lewis of the Competitive Enterprise Institute has written a definitive 120-page point-by-point\n",
            "3 últimas amostras treino:\n",
            "True This 1986 Italian-French remake of the 1946 film of the same name turns up the heat early, and doesn\n",
            "False After perusing the large amount of comments on this movie it is clear that there are two kinds of sc\n",
            "False As a youth pastor I heard good things about this movie. Then I watched it. The acting wasn't the bes\n",
            "3 primeiras amostras validação:\n",
            "True After watching \"The Bodyguard\" last night, I felt compelled to write a review of it.<br /><br />This\n",
            "True I'm sorry but this is just plain pathetic. The little girl was a brat, their were no enjoyable chara\n",
            "True this film is absolutely hilarious. basically, the plot revolves around a serial killer being somehow\n",
            "3 últimas amostras validação:\n",
            "False I read some gushing reviews here on IMDb and thought I would give this movie a look. Disappointed. O\n",
            "False He pulled the guys guts out his butt! That's a spoof right?! No one really writes that it just happe\n",
            "True 'Una Giornata Particolare' is a movie that has a title that sounds so familiar I thought I had seen \n"
          ]
        }
      ]
    }
  ]
}