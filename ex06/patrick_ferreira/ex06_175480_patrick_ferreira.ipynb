{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-79e5302d",
   "language": "python",
   "display_name": "PyCharm (IA024_2022S2)"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c5f5f5741c2d44a58484f9875deac7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_31b2f449c7ea4c2894a1c6b52e1b562d",
       "IPY_MODEL_02cbcb8712d04d7ea08c9c85352f6a4b",
       "IPY_MODEL_a8d5a647b70e4725acbc02b30c130e26"
      ],
      "layout": "IPY_MODEL_e09ab2a1da33496fbe170cb83b3bedc2"
     }
    },
    "31b2f449c7ea4c2894a1c6b52e1b562d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89dc690231c04207934eccffca21df9b",
      "placeholder": "​",
      "style": "IPY_MODEL_0e2b3eaec6134b60ac83d3de32581c4a",
      "value": "Downloading: 100%"
     }
    },
    "02cbcb8712d04d7ea08c9c85352f6a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a6db4e9836d47669b0c3fc01c41ef67",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe8451caf3074b17a19a60e324ac3e59",
      "value": 440473133
     }
    },
    "a8d5a647b70e4725acbc02b30c130e26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec4f8edbb77a4e2593014618df68c8c8",
      "placeholder": "​",
      "style": "IPY_MODEL_2486724b245c43b3859c271a582b06bd",
      "value": " 440M/440M [00:10&lt;00:00, 28.3MB/s]"
     }
    },
    "e09ab2a1da33496fbe170cb83b3bedc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89dc690231c04207934eccffca21df9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e2b3eaec6134b60ac83d3de32581c4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6db4e9836d47669b0c3fc01c41ef67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe8451caf3074b17a19a60e324ac3e59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec4f8edbb77a4e2593014618df68c8c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2486724b245c43b3859c271a582b06bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/patrickctrf/IA024_2022S2/blob/main/ex06/patrick_ferreira/ex06_175480_patrick_ferreira.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mJenlw_1lcTx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook de referência \n",
    "\n",
    "Nome: Patrick de Carvalho Tavares Rezende Ferreira"
   ],
   "metadata": {
    "collapsed": false,
    "id": "L8QxlyoBlcT2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instruções:\n",
    "\n",
    "\n",
    "Treinar e medir a acurácia de um modelo BERT (ou variantes) para classificação binária usando o dataset do IMDB (20k/5k amostras de treino/validação).\n",
    "\n",
    "Importante: \n",
    "- Deve-se implementar o próprio laço de treinamento.\n",
    "- Implementar o acumulo de gradiente.\n",
    "\n",
    "Dicas:\n",
    "- BERT geralmente costuma aprender bem uma tarefa com poucas épocas (de 3 a 5 épocas). Se tiver demorando mais de 5 épocas para chegar em 80% de acurácia, ajuste os hiperparametros.\n",
    "\n",
    "- Solução para erro de memória:\n",
    "  - Usar bfloat16 permite quase dobrar o batch size\n",
    "\n",
    "Opcional:\n",
    "- Pode-se usar a função trainer da biblioteca Transformers/HuggingFace para verificar se seu laço de treinamento está correto. Note que ainda assim é obrigatório implementar o laço próprio.\n",
    "\n",
    "- Usar pytorch lightning. Para entender como o pytorch lightning funciona, veja uma implementação simplificada no notebook `06_01_Treino_Validação_MNIST_Lightning_Lite.ipynb`"
   ],
   "metadata": {
    "collapsed": false,
    "id": "jNJ_9HN5lcT3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fixando a seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print('Using {}'.format(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparando Dados"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Exi-qvMYlcT8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Primeiro, fazemos download do dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "In2OqfzQlcT8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File ‘aclImdb.tgz’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc http://files.fast.ai/data/aclImdb.tgz\n",
    "!tar -xzf aclImdb.tgz"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yKuSVItIlcT9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "002cc2db-737f-4ccf-d253-0f6454972450"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "il-v4h6LlcT-",
    "outputId": "e777f591-d48c-4924-beb4-8254257f4c1c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carregando o dataset\n",
    "\n",
    "Criaremos uma divisão de treino (20k exemplos) e validação (5k exemplos) artificialmente."
   ],
   "metadata": {
    "collapsed": false,
    "id": "nxEmcSZOlcT-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]\u001B[A\n",
      " 31%|███       | 3867/12500 [00:00<00:00, 38664.14it/s]\u001B[A\n",
      " 62%|██████▏   | 7734/12500 [00:00<00:00, 37682.83it/s]\u001B[A\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 36211.19it/s]\n",
      "\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]\u001B[A\n",
      " 31%|███       | 3860/12500 [00:00<00:00, 38594.42it/s]\u001B[A\n",
      " 62%|██████▏   | 7720/12500 [00:00<00:00, 36209.32it/s]\u001B[A\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 35900.20it/s]\n",
      "\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]\u001B[A\n",
      " 32%|███▏      | 3960/12500 [00:00<00:00, 39595.98it/s]\u001B[A\n",
      " 63%|██████▎   | 7920/12500 [00:00<00:00, 39168.76it/s]\u001B[A\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 37990.98it/s]\n",
      "\n",
      "  0%|          | 0/12500 [00:00<?, ?it/s]\u001B[A\n",
      " 28%|██▊       | 3456/12500 [00:00<00:00, 34550.23it/s]\u001B[A\n",
      " 56%|█████▌    | 6994/12500 [00:00<00:00, 35024.69it/s]\u001B[A\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 35518.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20000 amostras de treino.\n",
      "5000 amostras de desenvolvimento.\n",
      "25000 amostras de teste.\n",
      "3 primeiras amostras treino:\n",
      "False As low budget indies go, you will usually find that you get what you pay for, and let me just say, I\n",
      "False The DVD was a joke, the audio for the first few minutes was terrible with sound out of sync and Sega\n",
      "True When i was told of this movie i thought it would be another chick flick. I was wrong. This movie sen\n",
      "3 últimas amostras treino:\n",
      "False Kubrick meets King. It sounded so promising back in the spring of 1980, I remember. Then the movie c\n",
      "True Richard Willaims is an animation god. He was hampered in directing this film by the producer. The fi\n",
      "True 'Panic in the Streets (1950)' owes more to British noir that its American counterparts. Like Reed's \n",
      "3 primeiras amostras validação:\n",
      "True I just got back from a screening a couple of hours ago, and I was very happy with the movie when I l\n",
      "True \"Panic\" is a captivating, blurred-genre film about a brooding and conflicted middle aged hitman's re\n",
      "True The past creeps up on a rehab-addict when he reconnects with his ill brother and a former girlfriend\n",
      "3 últimas amostras validação:\n",
      "True Orson Welles manages to knock me on my ass with every picture of his I see. Lady of Shanghai is on t\n",
      "True Being that this movie has a lot of fine entertainment qualities I think it should some more credit t\n",
      "True Wow I loved this movie! It is about normal life in a small village. About hypocrisy and honesty, lov\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "max_valid = 5000\n",
    "\n",
    "def load_texts(folder):\n",
    "    texts = []\n",
    "    for path in tqdm(os.listdir(folder)):\n",
    "        with open(os.path.join(folder, path)) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "x_train_pos = load_texts(os.path.join(cwd,'aclImdb' + os.sep + 'train' + os.sep + 'pos'))\n",
    "x_train_neg = load_texts(os.path.join(cwd,'aclImdb' + os.sep + 'train' + os.sep + 'neg'))\n",
    "x_test_pos = load_texts(os.path.join(cwd, 'aclImdb' + os.sep + 'test' + os.sep + 'pos'))\n",
    "x_test_neg = load_texts(os.path.join(cwd, 'aclImdb' + os.sep + 'test' + os.sep + 'neg'))\n",
    "\n",
    "x_train = x_train_pos + x_train_neg\n",
    "x_test = x_test_pos + x_test_neg\n",
    "y_train = [True] * len(x_train_pos) + [False] * len(x_train_neg)\n",
    "y_test = [True] * len(x_test_pos) + [False] * len(x_test_neg)\n",
    "\n",
    "# Embaralhamos o treino para depois fazermos a divisão treino/valid.\n",
    "c = list(zip(x_train, y_train))\n",
    "random.shuffle(c)\n",
    "x_train, y_train = zip(*c)\n",
    "\n",
    "x_valid = x_train[-max_valid:]\n",
    "y_valid = y_train[-max_valid:]\n",
    "x_train = x_train[:-max_valid]\n",
    "y_train = y_train[:-max_valid]\n",
    "\n",
    "print(len(x_train), 'amostras de treino.')\n",
    "print(len(x_valid), 'amostras de desenvolvimento.')\n",
    "print(len(x_test), 'amostras de teste.')\n",
    "\n",
    "print('3 primeiras amostras treino:')\n",
    "for x, y in zip(x_train[:3], y_train[:3]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 últimas amostras treino:')\n",
    "for x, y in zip(x_train[-3:], y_train[-3:]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 primeiras amostras validação:')\n",
    "for x, y in zip(x_valid[:3], y_test[:3]):\n",
    "    print(y, x[:100])\n",
    "\n",
    "print('3 últimas amostras validação:')\n",
    "for x, y in zip(x_valid[-3:], y_valid[-3:]):\n",
    "    print(y, x[:100])\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "EQ4uY5UclcT_",
    "outputId": "a7f984f2-b728-4f5c-ee03-6efc54bf3922",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Criando classe do dataset\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts: List[str], labels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], torch.tensor([0., 1.]) if self.labels[idx] else torch.tensor([1., 0.])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KOYGMXazlcUA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dados de treino, validação e teste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "HFmpCmyllcUB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training examples: 20000\n",
      "valid examples: 5000\n",
      "test examples: 25000\n"
     ]
    }
   ],
   "source": [
    "training_dataset = MyDataset(x_train, y_train)\n",
    "valid_dataset = MyDataset(x_valid, y_valid)\n",
    "test_dataset = MyDataset(x_test, y_test)\n",
    "\n",
    "print(f'training examples: {len(training_dataset)}')\n",
    "print(f'valid examples: {len(valid_dataset)}')\n",
    "print(f'test examples: {len(test_dataset)}')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "JupqAjoilcUC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "afc5d09a-f88e-4d68-f3bd-00e05cb1db55"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testando se o modelo processa os dados corretamente"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vlJZ_M-alcUC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5f5f5741c2d44a58484f9875deac7bd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "model.train().to(device)\n",
    "\n",
    "sample_train, _ = next(iter(DataLoader(training_dataset, batch_size=4)))\n",
    "\n",
    "sample_train = tokenizer.batch_encode_plus(sample_train, padding=True, return_tensors=\"pt\", truncation=True, max_length=200).to(device)\n",
    "\n",
    "model(**sample_train).logits.shape\n",
    "\n",
    "del sample_train\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "fpBCUOGglcUD",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "c5f5f5741c2d44a58484f9875deac7bd",
      "31b2f449c7ea4c2894a1c6b52e1b562d",
      "02cbcb8712d04d7ea08c9c85352f6a4b",
      "a8d5a647b70e4725acbc02b30c130e26",
      "e09ab2a1da33496fbe170cb83b3bedc2",
      "89dc690231c04207934eccffca21df9b",
      "0e2b3eaec6134b60ac83d3de32581c4a",
      "8a6db4e9836d47669b0c3fc01c41ef67",
      "fe8451caf3074b17a19a60e324ac3e59",
      "ec4f8edbb77a4e2593014618df68c8c8",
      "2486724b245c43b3859c271a582b06bd"
     ]
    },
    "outputId": "6d03bb91-c350-4db6-dec9-10c413ab0f97"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TREINAMENTO"
   ],
   "metadata": {
    "collapsed": false,
    "id": "TvxcBabNlcUD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/20000 [00:48<89:11:23, 16.06s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 steps; 0 examples so far; train loss: 0.12, valid loss: 0.28\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 15%|█▌        | 3003/20000 [06:27<20:31:38,  4.35s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000 steps; 3000 examples so far; train loss: 0.18, valid loss: 0.29\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 6003/20000 [12:06<16:57:48,  4.36s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2000 steps; 6000 examples so far; train loss: 0.11, valid loss: 0.39\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 45%|████▌     | 9003/20000 [17:46<13:44:41,  4.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3000 steps; 9000 examples so far; train loss: 0.07, valid loss: 0.48\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 12003/20000 [23:25<9:42:05,  4.37s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4000 steps; 12000 examples so far; train loss: 0.06, valid loss: 0.45\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 75%|███████▌  | 15003/20000 [29:05<6:07:07,  4.41s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5000 steps; 15000 examples so far; train loss: 0.04, valid loss: 0.43\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 18003/20000 [34:46<2:26:16,  4.39s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6000 steps; 18000 examples so far; train loss: 0.03, valid loss: 0.45\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "20001it [38:04,  8.75it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "max_examples = 20_000\n",
    "eval_every_steps = 1000\n",
    "lr = 4e-5\n",
    "use_amp = True\n",
    "\n",
    "train_loader = DataLoader(training_dataset, batch_size=16, shuffle=True, num_workers=1)\n",
    "validation_loader = DataLoader(valid_dataset, batch_size=16, num_workers=1, )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.9, min_lr=3e-5, patience=15000, threshold=1e-1, verbose=True)\n",
    "scaler=GradScaler()\n",
    "\n",
    "\n",
    "def train_step(input_ids, target_ids):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    with autocast(enabled=use_amp):\n",
    "        logits = model(**input_ids).logits\n",
    "        logits = logits.reshape(-1, logits.shape[-1])\n",
    "    loss = nn.functional.cross_entropy(logits, target_ids, )\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validation_step(input_ids, target_ids):\n",
    "    model.eval()\n",
    "    with autocast(enabled=use_amp):\n",
    "        logits = model(**input_ids).logits\n",
    "        loss = nn.functional.cross_entropy(logits, target_ids,)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        accuracy = (preds == target_ids.argmax(dim=1)).sum().float() / logits.shape[0]\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "best_validation_loss = 9999\n",
    "train_losses = []\n",
    "n_examples = 0\n",
    "step = 0\n",
    "pbar = tqdm(total=max_examples)\n",
    "while n_examples < max_examples:\n",
    "    for train_input_ids, train_target_ids in train_loader:\n",
    "        train_input_ids = tokenizer.batch_encode_plus(train_input_ids, padding=True, return_tensors=\"pt\", truncation=True, max_length=200).to(device)\n",
    "        loss = train_step(train_input_ids, train_target_ids.to(device))\n",
    "        train_losses.append(loss)\n",
    "\n",
    "        # LR scheduler\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if step % eval_every_steps == 0:\n",
    "            train_loss = np.average(train_losses)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_loss = np.average([\n",
    "                    validation_step(tokenizer.batch_encode_plus(val_input_ids, padding=True, return_tensors=\"pt\", truncation=True, max_length=200).to(device), val_target_ids.to(device))[0]\n",
    "                    for val_input_ids, val_target_ids in validation_loader])\n",
    "                # Checkpoint to best models found.\n",
    "                if best_validation_loss > valid_loss:\n",
    "                    # Update the new best perplexity.\n",
    "                    best_validation_loss = valid_loss\n",
    "                    model.eval()\n",
    "                    torch.save(model, \"best_model.pth\")\n",
    "\n",
    "            print(f'{step} steps; {n_examples} examples so far; train loss: {train_loss:.2f}, valid loss: {valid_loss:.2f}')\n",
    "            train_losses = []\n",
    "\n",
    "        n_examples += len(train_input_ids)  # Increment of batch size\n",
    "        step += 1\n",
    "        pbar.update(len(train_input_ids))\n",
    "        if n_examples >= max_examples:\n",
    "            break\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Restore best model (checkpoint) found\n",
    "model = torch.load(\"best_model.pth\")\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "bSZVvtnwlcUD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4990d64f-32cb-4755-def9-2969aa818ce6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avaliação no dataset de Teste"
   ],
   "metadata": {
    "collapsed": false,
    "id": "kvCF-sZMlcUE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 25/25 [03:36<00:00,  8.65s/it]\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "with torch.no_grad():\n",
    "    losses = [\n",
    "        validation_step(tokenizer.batch_encode_plus(input, padding=True, return_tensors=\"pt\", truncation=True, max_length=200).to(device), target.to(device))\n",
    "        for input, target in tqdm(test_loader)\n",
    "    ]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Sb2Wh1WXlcUE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "322ea880-5843-458f-f6b2-4700dac84e63"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "losses = list(zip(*losses))\n",
    "\n",
    "test_loss, test_accuracy = np.average(losses[0]), torch.mean(torch.tensor(losses[1]).float())\n",
    "\n",
    "print(f'test loss: {test_loss}', f'test acc: {test_accuracy}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVVjtas8tfCD",
    "outputId": "d34dd021-de4b-4a7d-d491-08202f424e84"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test loss: 0.25690659701824187 test acc: 91.10171508789062\n"
     ]
    }
   ]
  }
 ]
}